{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51aa53d",
   "metadata": {},
   "source": [
    "# Combine all PDF files into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed06c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59935cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama list\n",
    "# !ollama pull gemma3:12b\n",
    "#!ollama rm gemma3:4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02319b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pdf_dir = '/Users/avosseler/Business Trips/2025/Barcelona' \n",
    "os.listdir(pdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ec631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_analysis.utils.utils import merge_pdfs\n",
    "\n",
    "merge_pdfs(pdf_dir, pdf_names=[\"flight.pdf\", \"car_sharing_first_day.pdf\"], output_file='merged.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out chunker library\n",
    "# uv add chonkie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfMerger\n",
    "import os\n",
    "\n",
    "# Set the directory containing your PDFs\n",
    "os.chdir(pdf_dir)\n",
    "\n",
    "# Create a PdfMerger object\n",
    "merger = PdfMerger()\n",
    "#print(os.listdir(pdf_dir))\n",
    "\n",
    "first_file = \"Travel Expense Barcelona.pdf\"\n",
    "\n",
    "merger.merge(0, first_file)\n",
    "print(f'Adding {first_file}...')\n",
    "\n",
    "# Loop through all PDF files in the directory and append them\n",
    "for page_number, file in enumerate(sorted(os.listdir(\".\")), start=1):\n",
    "    if file.endswith('.pdf') and file != first_file:\n",
    "        print(f'Appending {file}...')\n",
    "        # merger.append(file)\n",
    "        merger.merge(page_number, file)\n",
    "\n",
    "\n",
    "# Write out the merged PDF\n",
    "merger.write('combined_invoice.pdf')\n",
    "merger.close()\n",
    "print('Merged PDF created as combined PDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8a633",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ee6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_dir = '/Users/avosseler/Business Trips/2025/Barcelona'\n",
    "file_name = 'Hotel_Taxi.pdf'\n",
    "\n",
    "with open(os.path.join(file_dir, file_name), 'rb') as f:\n",
    "    image_bytes = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "file_dir = '/Users/avosseler/Business Trips/2025/Barcelona'\n",
    "file_name = 'Hotel_Taxi.pdf'\n",
    "\n",
    "# Convert PDF to images\n",
    "images = convert_from_path(os.path.join(file_dir, file_name))\n",
    "\n",
    "# Save the first page as an image\n",
    "image_path = os.path.join(file_dir, 'Hotel_Taxi_Page1.png')\n",
    "images[0].save(image_path, 'PNG')\n",
    "print(f\"Saved first page as image: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "# Read the image as bytes\n",
    "with open(image_path, 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "prompt = \"Extract all text from this image and present it in Markdown format.\"\n",
    "prompt = \"What is the name of the guest in the hotel invoice? Extract the name.\"\n",
    "\n",
    "# Send the image to the Ollama model\n",
    "response = ollama.chat(\n",
    "    model='gemma3:12b',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "        'images': [image_bytes]\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacdf942",
   "metadata": {},
   "source": [
    "### LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9466c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        buffered = BytesIO()\n",
    "        img.save(buffered, format=\"PNG\")  # or \"PNG\" if appropriate\n",
    "        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93453d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "image_path = os.path.join(file_dir, 'Hotel_Taxi_Page1.png')\n",
    "\n",
    "# Encode the image\n",
    "image_b64 = encode_image_to_base64(image_path=image_path)\n",
    "\n",
    "query = \"Extract all text from this image and present it in Markdown format.\"\n",
    "query = \"What is the name of the guest in the hotel invoice?\"\n",
    "query = \"What is the total amount in Euro on the invoice? You will find the final amount at the end of the invoice.\"\n",
    "query = \"What is the arrival date of the guest?\"\n",
    "query = \"What is the departure date of the guest?\"\n",
    "\n",
    "\n",
    "content_parts = [\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": f\"data:image/png;base64,{image_b64}\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": query\n",
    "    }\n",
    "]\n",
    "\n",
    "message = HumanMessage(content=content_parts)\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:12b\", temperature=0.2, max_tokens=2000)\n",
    "\n",
    "response = llm.invoke([message])\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa2c42b",
   "metadata": {},
   "source": [
    "## Docling OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defea86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_analysis.resources.document_processor import DocumentProcessor\n",
    "import os\n",
    "\n",
    "file_name = 'Hotel_Taxi.pdf'\n",
    "#file_name = \"taxi_to_airport_barc.pdf\"\n",
    "#file_name = \"car_sharing_first_day.pdf\"\n",
    "#file_name = \"flight.pdf\"\n",
    "\n",
    "file_path = os.path.join('/Users/avosseler/Business Trips/2025/Barcelona', file_name)\n",
    "\n",
    "dproc = DocumentProcessor(file_path=file_path)\n",
    "document = dproc.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f695af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document.texts\n",
    "# document.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dproc.display_markdown()\n",
    "\n",
    "markdown = document.export_to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_analysis.resources.invoice_classifier import InvoiceDetector\n",
    "\n",
    "clf = InvoiceDetector()\n",
    "\n",
    "await clf.adetect(input_text=markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1b526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10453221",
   "metadata": {},
   "source": [
    "Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbaaaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Buchungsinformationen\n",
       "\n",
       "Details zur Abholung\n",
       "\n",
       "Abgeschlossen Letzte Aktualisierung: 31 Aug. um 12:32 Uhr\n",
       "\n",
       "## Ihre Buchungsinformationen\n",
       "\n",
       "Bestätigungsnummer: 144119682\n",
       "\n",
       "## Reisedetails\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Flugverfolgung hinzugefügt\n",
       "\n",
       "Ihre Abholzeit richtet sich nach der Ankunftszeit Ihres Flugs\n",
       "\n",
       "Der Fahrer wird Ihren Flug im Auge behalten und die Abholzeit im Falle von Verspätungen anpassen. Nach seiner Ankunft wartet der Fahrer 45 Minuten, sodass Sie Zeit haben; vom Flugzeug zum Treffpunkt zu gelangen.\n",
       "\n",
       "## Flugnummer\n",
       "\n",
       "LH1678\n",
       "\n",
       "## Angaben zu Abholung und Rückgabe\n",
       "\n",
       "Mo. 25. Aug-\n",
       "\n",
       "Budapest Liszt Ferenc International Airport (BUD) , Budapest, 1185 Ungarn\n",
       "\n",
       "38 Min\n",
       "\n",
       "Mo. 25. Aug. (ungefähr)\n",
       "\n",
       "Four Points by Sheraton Budapest Danube, Budapest, Pozsonyi út 79, 1133 Ungarn\n",
       "\n",
       "Standard\n",
       "\n",
       "Bereitgestellt von Hungary Private Transfers\n",
       "\n",
       "Fahrgastauswahl\n",
       "\n",
       "Maximal Fahrgast\n",
       "\n",
       "Kontaktdaten\n",
       "\n",
       "Alexander Vosseler +4917621942264 a.vosseler@gmx.net\n",
       "\n",
       "## Preisübersicht\n",
       "\n",
       "Einzelfahrt\n",
       "\n",
       "30,21 €\n",
       "\n",
       "Gesamtpreis\n",
       "\n",
       "30,21 €\n",
       "\n",
       "Einschließlich aller Steuern und Gebühren\n",
       "\n",
       "## Wie können wir Ihnen helfen?\n",
       "\n",
       "Zu den Hilfeseiten\n",
       "\n",
       "Kundenservice ist rund um die Uhr verfügbar\n",
       "\n",
       "## Benötigen Sie eine Rückfahrt?\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Suche\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Gespeichert\n",
       "\n",
       "Buchungen\n",
       "\n",
       "<!-- image -->"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from IPython.display import Markdown, display\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "#file_name = 'Taxi_from_Budapest_Airport_to_Hotel_Day1.pdf'\n",
    "file_name = \"Taxi_from_Budapest_Airport_to_Hotel_BookingCom.png\"\n",
    "folder_name = 'Graphisoft-Budapest-Aug/Taxi'\n",
    "\n",
    "file_path = os.path.join('/Users/avosseler/Business Trips/2025', folder_name, file_name)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Your existing Docling code\n",
    "    converter = DocumentConverter()\n",
    "    result = converter.convert(\n",
    "        file_path,     \n",
    "    )    \n",
    "    markdown = result.document.export_to_markdown()\n",
    "    \n",
    "display(Markdown(markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e48f846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Buchungsinformationen\n",
       "\n",
       "Details zur Abholung\n",
       "\n",
       "Abgeschlossen Letzte Aktualisierung: 31 Aug. um 12:32 Uhr\n",
       "\n",
       "## Ihre Buchungsinformationen\n",
       "\n",
       "Bestätigungsnummer: 144119682\n",
       "\n",
       "## Reisedetails\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Flugverfolgung hinzugefügt\n",
       "\n",
       "Ihre Abholzeit richtet sich nach der Ankunftszeit Ihres Flugs\n",
       "\n",
       "Der Fahrer wird Ihren Flug im Auge behalten und die Abholzeit im Falle von Verspätungen anpassen. Nach seiner Ankunft wartet der Fahrer 45 Minuten, sodass Sie Zeit haben; vom Flugzeug zum Treffpunkt zu gelangen.\n",
       "\n",
       "## Flugnummer\n",
       "\n",
       "LH1678\n",
       "\n",
       "## Angaben zu Abholung und Rückgabe\n",
       "\n",
       "Mo. 25. Aug-\n",
       "\n",
       "Budapest Liszt Ferenc International Airport (BUD) , Budapest, 1185 Ungarn\n",
       "\n",
       "38 Min\n",
       "\n",
       "Mo. 25. Aug. (ungefähr)\n",
       "\n",
       "Four Points by Sheraton Budapest Danube, Budapest, Pozsonyi út 79, 1133 Ungarn\n",
       "\n",
       "Standard\n",
       "\n",
       "Bereitgestellt von Hungary Private Transfers\n",
       "\n",
       "Fahrgastauswahl\n",
       "\n",
       "Maximal Fahrgast\n",
       "\n",
       "Kontaktdaten\n",
       "\n",
       "Alexander Vosseler +4917621942264 a.vosseler@gmx.net\n",
       "\n",
       "## Preisübersicht\n",
       "\n",
       "Einzelfahrt\n",
       "\n",
       "30,21 €\n",
       "\n",
       "Gesamtpreis\n",
       "\n",
       "30,21 €\n",
       "\n",
       "Einschließlich aller Steuern und Gebühren\n",
       "\n",
       "## Wie können wir Ihnen helfen?\n",
       "\n",
       "Zu den Hilfeseiten\n",
       "\n",
       "Kundenservice ist rund um die Uhr verfügbar\n",
       "\n",
       "## Benötigen Sie eine Rückfahrt?\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Suche\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Gespeichert\n",
       "\n",
       "Buchungen\n",
       "\n",
       "<!-- image -->"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TesseractOcrOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "pipeline_options.ocr_options = TesseractOcrOptions(lang=[\"eng\"])  # or use other OCR option classes\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    result = converter.convert(file_path)\n",
    "    \n",
    "markdown = result.document.export_to_markdown()\n",
    "display(Markdown(markdown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabe1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings, ChatVertexAI\n",
    "from finance_analysis.config import  global_config as glob\n",
    "\n",
    "embeddings = VertexAIEmbeddings(\n",
    "    model_name=\"text-embedding-005\",\n",
    "    project=glob.GCP_PROJECT\n",
    ")\n",
    "\n",
    "llm = ChatVertexAI(\n",
    "    model_name=\"gemini-2.5-flash-preview-04-17\",\n",
    "    temperature=0.2,\n",
    "    project=glob.GCP_PROJECT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aed32e5",
   "metadata": {},
   "source": [
    "Extract infos from Taxi invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class OutputStructure(BaseModel):\n",
    "    total_amount: str = Field(..., description=\"The total amount in Euro on the invoice. Use the format as 1234.56\")\n",
    "    issue_date: str = Field(..., description=\"The issue date of the invoice. Use the date format as DD.MM.YYYY\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=OutputStructure)\n",
    "\n",
    "taxi_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an intelligent assistant tasked with answering questions based on the provided context. \n",
    "    Use only the information in the context to answer the questions accurately. Provide the answers in JSON format.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Questions:\n",
    "    1. What is the total amount in Euro on the invoice? You will find the final amount at the end of the invoice.\n",
    "    2. What is the date of issue?\n",
    "\n",
    "    Please use the following output format:\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = taxi_prompt | llm | parser\n",
    "\n",
    "response = chain.invoke({\"context\": markdown})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8acb4b",
   "metadata": {},
   "source": [
    "Extract Infos from Hotel Invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995deb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class OutputStructure(BaseModel):\n",
    "    guest_name: str = Field(..., description=\"The name of the guest in the hotel invoice. Use the format as 'Firstname Lastname'\")\n",
    "    total_amount: str = Field(..., description=\"The total amount in Euro on the invoice. Use the format as 1234.56\")\n",
    "    start_date: str = Field(..., description=\"The arrival date of the guest. Use the date format as DD.MM.YYYY\")\n",
    "    end_date: str = Field(..., description=\"The departure date of the guest. Use the date format as DD.MM.YYYY\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=OutputStructure)\n",
    "\n",
    "hotel_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an intelligent assistant tasked with answering questions based on the provided context. \n",
    "    Use only the information in the context to answer the questions accurately. Provide the answers in JSON format.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Questions:\n",
    "    1. What is the name of the guest in the hotel invoice?\n",
    "    2. What is the total amount in Euro on the invoice? You will find the final amount at the end of the invoice.\n",
    "    3. What is the arrival date of the guest?\n",
    "    4. What is the departure date of the guest?\n",
    "\n",
    "    Please use the following output format:\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = hotel_prompt | llm | parser\n",
    "\n",
    "response = chain.invoke({\"context\": markdown})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_analysis.resources.document_processor import DocumentProcessor\n",
    "import os\n",
    "\n",
    "# file_name = 'Hotel_Taxi.pdf'\n",
    "# file_name = \"taxi_to_airport_barc.pdf\"\n",
    "# file_name = \"car_sharing_first_day.pdf\"\n",
    "file_name = \"flight.pdf\"\n",
    "\n",
    "file_path = os.path.join('/Users/avosseler/Business Trips/2025/Barcelona', file_name)\n",
    "\n",
    "# step 1: Process the document\n",
    "dproc = DocumentProcessor(file_path=file_path)\n",
    "document = dproc.process()\n",
    "markdown = document.export_to_markdown()\n",
    "\n",
    "# step 2: Extract entities\n",
    "from finance_analysis.resources.extractor import EntityExtractor\n",
    "\n",
    "ent = EntityExtractor(\"flight\")\n",
    "\n",
    "extracted = await ent.extract_entities(markdown)\n",
    "extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted[\"total_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "# from langchain_core.documents import Document\n",
    "\n",
    "# headers_to_split_on = [\n",
    "#     (\"#\", \"Header 1\"),\n",
    "#     (\"##\", \"Header 2\"),\n",
    "#     (\"###\", \"Header 3\"),\n",
    "# ]\n",
    "\n",
    "# markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "#     headers_to_split_on=headers_to_split_on,\n",
    "#     strip_headers=False\n",
    "# )\n",
    "\n",
    "# header_chunks = markdown_splitter.split_text(markdown)\n",
    "# len(header_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.create_documents([markdown])\n",
    "chunks\n",
    "\n",
    "# from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(\n",
    "#     chunk_size=1000,\n",
    "#     chunk_overlap=200\n",
    "# )\n",
    "\n",
    "# chunks = text_splitter.create_documents([markdown])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe478565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Answer using only this context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "query = \"What is the name of the guest in the hotel invoice?\"\n",
    "query = \"What is the total amount in Euro on the invoice? You will find the final amount at the end of the invoice.\"\n",
    "query = \"What is the arrival date of the guest?\"\n",
    "query = \"What is the departure date of the guest?\"\n",
    "\n",
    "response = qa_chain.invoke({\n",
    "    \"query\": query\n",
    "})\n",
    "print(response[\"result\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042ff24",
   "metadata": {},
   "source": [
    "### Via Docling Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e3432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.chunking import HybridChunker\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "import os\n",
    "\n",
    "# Your existing Docling conversion\n",
    "file_dir = '/Users/avosseler/Business Trips/2025/Barcelona'\n",
    "file_name = 'Hotel_Taxi.pdf'\n",
    "file_path = os.path.join(file_dir, file_name)\n",
    "\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "loader = DoclingLoader(\n",
    "    file_path=file_path,\n",
    "    export_type=ExportType.DOC_CHUNKS,\n",
    "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Answer using only this context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the name of the guest in the hotel invoice? Extract the name.\"\n",
    "query = \"What is the total amount due on the invoice?\"\n",
    "\n",
    "response = qa_chain.invoke({\n",
    "    \"query\": query\n",
    "})\n",
    "\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b94e42a",
   "metadata": {},
   "source": [
    "# LangGraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe47f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_analysis.resources.document_processor import DocumentProcessor\n",
    "import os\n",
    "\n",
    "file_name = 'Hotel_Taxi.pdf'\n",
    "# file_name = \"taxi_to_airport_barc.pdf\"\n",
    "# file_name = \"car_sharing_first_day.pdf\"\n",
    "#file_name = \"flight.pdf\"\n",
    "\n",
    "file_path = os.path.join('/Users/avosseler/Business Trips/2025/Barcelona', file_name)\n",
    "\n",
    "# step 1: Process the document\n",
    "dproc = DocumentProcessor(file_path=file_path)\n",
    "document = dproc.process()\n",
    "markdown = document.export_to_markdown()\n",
    "\n",
    "# step 2: Extract entities\n",
    "from finance_analysis.resources.extractor import EntityExtractor\n",
    "\n",
    "ent = EntityExtractor(\"flight\")\n",
    "\n",
    "extracted = ent.extract_entities(markdown)\n",
    "extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7da169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_analysis.resources.invoice_classifier import InvoiceDetector\n",
    "\n",
    "clf = InvoiceDetector()\n",
    "\n",
    "result = await clf.adetect(input_text=markdown)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6814585d",
   "metadata": {},
   "source": [
    "### Singe file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57241f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from finance_analysis.resources.extractor import EntityExtractor\n",
    "from finance_analysis.resources.document_processor import DocumentProcessor\n",
    "from finance_analysis.resources.invoice_classifier import InvoiceDetector\n",
    "\n",
    "\n",
    "# 1) Define the graph state\n",
    "class DocState(TypedDict):\n",
    "    file_name: str\n",
    "    processed_doc: str\n",
    "    invoice_type: str  \n",
    "    entities: Annotated[list[dict[str, str]], add]    # must be a list for concatenation\n",
    "\n",
    "\n",
    "# 2) Document-processing node \n",
    "def process_document(state: DocState) -> dict[str, str]:\n",
    "    print(\"Processing document...\")    \n",
    "    file_path = os.path.join('/Users/avosseler/Business Trips/2025/Barcelona', state[\"file_name\"])\n",
    "\n",
    "    # step 1: Process the document\n",
    "    dproc = DocumentProcessor(file_path=file_path)\n",
    "    document = dproc.process()\n",
    "    processed = document.export_to_markdown()\n",
    "\n",
    "    return {\"processed_doc\": processed}\n",
    "\n",
    "# 3) Entity-extraction node \n",
    "async def extract_entities(state: DocState) -> dict[str, list[dict[str, str]]]:\n",
    "    print(\"Extracting entities...\")\n",
    "    \n",
    "    ent = EntityExtractor(state[\"invoice_type\"])\n",
    "\n",
    "    extracted = await ent.aextract_entities(state[\"processed_doc\"])\n",
    "    # print(extracted)\n",
    "    return {\"entities\": [extracted]}\n",
    "\n",
    "# 4) Invoice classification node \n",
    "async def classify_invoice(state: DocState) -> dict[str, str]:\n",
    "    print(\"Classifying invoice...\")\n",
    "    clf = InvoiceDetector()\n",
    "\n",
    "    result = await clf.adetect(input_text=state[\"processed_doc\"])\n",
    "    print(result)\n",
    "    return {\"invoice_type\": result['invoice_type']}\n",
    "\n",
    "# Conditional routing after processing\n",
    "def should_classify(state: DocState) -> Literal[\"classify\", \"end\"]:\n",
    "    if len(state[\"processed_doc\"]) > 0:\n",
    "        return \"classify\"\n",
    "    return \"end\"\n",
    "\n",
    "# Conditional routing after classification\n",
    "def should_extract(state: DocState) -> Literal[\"extract\", \"end\"]:\n",
    "    if state.get(\"invoice_type\"):\n",
    "        return \"extract\"\n",
    "    return \"end\"\n",
    "\n",
    "\n",
    "# 5) Build the graph\n",
    "builder = StateGraph(DocState)\n",
    "builder.add_node(\"process\", process_document)\n",
    "builder.add_node(\"classify\", classify_invoice)\n",
    "builder.add_node(\"extract\", extract_entities)\n",
    "builder.add_edge(START, \"process\")\n",
    "\n",
    "# Set static edges (vs dynamically added edges via Command commands)\n",
    "\n",
    "# After processing, classify if possible\n",
    "builder.add_conditional_edges(\n",
    "    \"process\",\n",
    "    should_classify,\n",
    "    {\n",
    "        \"classify\": \"classify\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After classification, extract entities if possible\n",
    "builder.add_conditional_edges(\n",
    "    \"classify\",\n",
    "    should_extract,\n",
    "    {\n",
    "        \"extract\": \"extract\",     # If should_extract returns \"extract\", the workflow moves to the \"extract\" node\n",
    "        \"end\": END                # If should_extract returns \"end\", the workflow terminates (END is a special constant)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Connect extraction to end\n",
    "builder.add_edge(\"extract\", END)\n",
    "\n",
    "# Compile graph\n",
    "processor_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(processor_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Hotel_Taxi.pdf'\n",
    "file_name = \"taxi_to_airport_barc.pdf\"\n",
    "file_name = \"car_sharing_first_day.pdf\"\n",
    "file_name = \"flight.pdf\"\n",
    "\n",
    "result = await processor_graph.ainvoke({\"file_name\": file_name})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb130d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98a9f248",
   "metadata": {},
   "source": [
    "### Loop over list of names. Use dynamic routing/edges via Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import TypedDict, Annotated, Dict\n",
    "from operator import add\n",
    "import requests\n",
    "from langgraph.graph import END\n",
    "from langgraph.types import Command\n",
    "#from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from finance_analysis.utils.prompts import summary_prompt\n",
    "from finance_analysis.config import  global_config as glob\n",
    "from finance_analysis.utils.utils import create_conversion_info\n",
    "\n",
    "from finance_analysis.resources.extractor import EntityExtractor\n",
    "from finance_analysis.resources.document_processor import DocumentProcessor\n",
    "from finance_analysis.resources.invoice_classifier import InvoiceDetector\n",
    "from finance_analysis.utils.data_models import CurrencyCodeLiteral\n",
    "from finance_analysis.utils.utils import update_travel_expense_xlsx\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "directory = \"Graphisoft, Budapest, Mar\"\n",
    "#directory = \"Barcelona\"\n",
    "root_directory = '/Users/avosseler/Business Trips/2025'\n",
    "target_dir = os.path.join(root_directory, directory)\n",
    "\n",
    "\n",
    "class DocState(TypedDict):\n",
    "    file_names: list[str]  # List of files to process\n",
    "    current_file_index: int     # Index of the current file\n",
    "    file_name: str         # Name of the current file\n",
    "    processed_doc: str\n",
    "    invoice_type: str\n",
    "    entities: Annotated[list[dict[str, str]], add]\n",
    "    inferred_types: Annotated[list[str], add]      # collect all inferred types\n",
    "    currencies: Annotated[list[CurrencyCodeLiteral], add]  # collect all currencies\n",
    "    descriptions: Annotated[list[str], add]       # describe each invoice, Hotel Name, etc.\n",
    "    summary: str  # Summary of the processed documents\n",
    "    rate_info: str  # Information about exchange rates\n",
    "    \n",
    "# Load the next file node\n",
    "def load_next_file(state: DocState) -> Command:\n",
    "    index = state.get(\"current_file_index\", 0)\n",
    "    file_list = state.get(\"file_names\", [])\n",
    "    \n",
    "    # Finally: Goto Summarization if no more files\n",
    "    if index >= len(file_list):\n",
    "        return Command(goto=\"summarize\")\n",
    "    \n",
    "    print(f\"\\nLoading file: {file_list[index]}\")\n",
    "    return Command(\n",
    "        update={\n",
    "            \"file_name\": file_list[index],\n",
    "            \"current_file_index\": index + 1\n",
    "        },\n",
    "        goto=\"process\"          # next step (-> edge)\n",
    "    )\n",
    "\n",
    "# Document-processing node \n",
    "def process_document(state: DocState) -> Command:\n",
    "    print(\"Processing document...\")    \n",
    "    file_path = os.path.join(target_dir, state[\"file_name\"])\n",
    "\n",
    "    dproc = DocumentProcessor(file_path=file_path)\n",
    "    document = dproc.process()\n",
    "    processed = document.export_to_markdown()\n",
    "    return Command(update={\"processed_doc\": processed}, goto=\"classify\")\n",
    "\n",
    "\n",
    "async def extract_and_convert(state: DocState) -> Command:\n",
    "    \n",
    "    # pull raw entities\n",
    "    extracted = await EntityExtractor(state[\"invoice_type\"])\\\n",
    "                           .aextract_entities(state[\"processed_doc\"])\n",
    "                           \n",
    "    # Convert immediately\n",
    "    amount = float(extracted[\"total_amount\"])\n",
    "    from_cur = extracted[\"currency\"]\n",
    "    \n",
    "    print(f\"Converting {amount} {from_cur} to EUR...\")\n",
    "    conv = convert_currency(amount, from_cur)\n",
    "    print(f\"Converted amount: {conv['EUR Amount']} EUR\")\n",
    "    \n",
    "    extracted[\"total_amount\"] = conv[\"EUR Amount\"]\n",
    "    extracted[\"currency\"] = \"EUR\"\n",
    "    extracted[\"invoice_type\"] = state[\"invoice_type\"]\n",
    "\n",
    "    # stash both original + conversion, then loop back\n",
    "    return Command(\n",
    "        update={\n",
    "            \"entities\": [extracted],\n",
    "            \"conversion_result\": conv,\n",
    "            \"currencies\": [from_cur],      # must be list for concatenation, as you use the 'add' operator above\n",
    "            \"descriptions\": [extracted.get(\"description\", \"No description provided\")]\n",
    "        },\n",
    "        goto=\"load\"\n",
    "    )\n",
    "\n",
    "# Invoice classification node \n",
    "async def classify_invoice(state: DocState) -> Command:\n",
    "    \n",
    "    print(\"Classifying invoice...\")\n",
    "    clf = InvoiceDetector()\n",
    "    result = await clf.adetect(input_text=state[\"processed_doc\"])\n",
    "    \n",
    "    print(result['invoice_type'])\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"invoice_type\": result['invoice_type'],\n",
    "            \"inferred_types\": [result['invoice_type']]\n",
    "        },\n",
    "        goto=\"extract\"\n",
    "    )\n",
    "    \n",
    "# @tool\n",
    "# def sum_calculator(numbers: list[int]) -> int:\n",
    "#     \"\"\"\n",
    "#     A simple tool to calculate the sum of a list of numbers.\n",
    "\n",
    "#     Args:\n",
    "#         numbers (list[int]): A list of integers to sum up.\n",
    "\n",
    "#     Returns:\n",
    "#         int: The total sum of the numbers in the list.\n",
    "#     \"\"\"\n",
    "#     if not isinstance(numbers, list):\n",
    "#         raise ValueError(\"Input should be a list of integers.\")\n",
    "#     if not all(isinstance(num, int) for num in numbers):\n",
    "#         raise ValueError(\"All elements in the list should be integers.\")\n",
    "#     return sum(numbers)\n",
    "\n",
    "\n",
    "#@tool(\"convert_currency\", return_direct=True)\n",
    "def convert_currency(\n",
    "    amount: float,\n",
    "    from_currency: CurrencyCodeLiteral,\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Convert a monetary amount from one currency to another via api.frankfurter.app\n",
    "\n",
    "    Args:\n",
    "        amount (float): Input amount to convert\n",
    "        from_currency (CurrencyCodeLiteral): Abbreviation of the currency to convert from, e.g. \"USD\"\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing the converted amount and the date of conversion\n",
    "    \"\"\"\n",
    "    if from_currency == \"EUR\":\n",
    "        return {\"EUR Amount\": amount, \"Exchange Rate - Date\": \"N/A\"}\n",
    "    \n",
    "    # If currency is not Euro, convert to Euro:\n",
    "    resp = requests.get(\n",
    "        \"https://api.frankfurter.app/latest\",\n",
    "        params={\"amount\": f\"{amount}\", \"from\": f\"{from_currency.upper()}\", \"to\": \"EUR\"},\n",
    "        timeout=5, verify=False     # no ssl verification\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    euro_amount = resp.json()[\"rates\"].get(\"EUR\")     # Converted amount in EUR\n",
    "    date = resp.json()[\"date\"]\n",
    "    print(resp.json())\n",
    "    return {\"EUR Amount\": euro_amount, \"Exchange Rate - Date\": date}\n",
    "\n",
    "\n",
    "async def summarize(state: DocState) -> Command:\n",
    "    \"\"\"\n",
    "    Generates a summary of extracted entities from the given document state.\n",
    "\n",
    "    This method logs the summarization process, ensures that entities are present in the state,\n",
    "    creates exchange rate information, and uses a prompt template with a language model to\n",
    "    generate a summary. The summary is then returned as part of a Command object to update the\n",
    "    state and proceed to the end of the workflow.\n",
    "\n",
    "    Args:\n",
    "        state (DocState): The current document state containing extracted entities and other relevant data.\n",
    "\n",
    "    Returns:\n",
    "        Command: A command object containing the generated summary and the next workflow step.\n",
    "    \"\"\"\n",
    "\n",
    "    assert \"entities\" in state, \"No entities found in the result.\"\n",
    "\n",
    "    rate_info = create_conversion_info(state)\n",
    "\n",
    "    llm = ChatVertexAI(\n",
    "        model_name=\"gemini-2.5-flash\",\n",
    "        temperature=0.1,\n",
    "        project=glob.GCP_PROJECT,\n",
    "    )\n",
    "\n",
    "    summary_templ = PromptTemplate(\n",
    "        template=summary_prompt,\n",
    "        input_variables=[\"context\", \"info_exchange_rate\"],\n",
    "    )\n",
    "\n",
    "    chain = summary_templ | llm\n",
    "\n",
    "    response = await chain.ainvoke(\n",
    "        {\"context\": state[\"entities\"], \"info_exchange_rate\": rate_info}\n",
    "    )\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"summary\": response.content,\n",
    "            \"rate_info\": rate_info,\n",
    "        },\n",
    "        # goto=END,\n",
    "        goto=\"update_xlsx\"  # Proceed to the next step\n",
    "    )\n",
    "    \n",
    "    \n",
    "def update_xlsx_file(state: DocState) -> Command:\n",
    "    \"\"\"\n",
    "    Placeholder for a method to edit an XLSX file based on the current state.\n",
    "    This method is not implemented yet.\n",
    "\n",
    "    Args:\n",
    "        state (DocState): The current processing state.\n",
    "\n",
    "    Returns:\n",
    "        Command: A command to proceed to the next step in the workflow.\n",
    "    \"\"\"\n",
    "    update_travel_expense_xlsx(result=state)\n",
    "    print(\"Updating XLSX file with the extracted data...\")\n",
    "    return Command(goto=END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "# from langgraph.prebuilt import ToolNode\n",
    "\n",
    "builder = StateGraph(DocState)\n",
    "\n",
    "# tool_node = ToolNode([sum_calculator])\n",
    "# builder.add_node(\"calculate sum\", tool_node)\n",
    "\n",
    "# # turn your function into a graph node\n",
    "# builder.add_node(\"convert\", ToolNode([convert_currency]))\n",
    "\n",
    "builder.add_node(\"load\", load_next_file)\n",
    "builder.add_node(\"process\", process_document)\n",
    "builder.add_node(\"classify\", classify_invoice)\n",
    "builder.add_node(\"extract\", extract_and_convert)\n",
    "builder.add_node(\"summarize\", summarize)\n",
    "builder.add_node(\"update_xlsx\", update_xlsx_file)\n",
    "builder.add_edge(START, \"load\")\n",
    "\n",
    "# This is only statically added here to see the edges in the visualization\n",
    "# the graph will be compiled with the edges added dynamically through the use of 'Command'\n",
    "# REMOVE THIS LATER: will cause recursive loop otherwise and an error!\n",
    "\n",
    "# builder.add_edge(\"load\", \"process\")\n",
    "# builder.add_edge(\"process\", \"classify\")\n",
    "# builder.add_edge(\"classify\", \"extract\")\n",
    "# builder.add_edge(\"extract\", \"load\").     # loop back to load next file\n",
    "# builder.add_edge(\"load\", \"summarize\")   # finally go to summarize\n",
    "# builder.add_edge(\"summarize\", \"update_xlsx\")\n",
    "# builder.add_edge(\"update_xlsx\", END)\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "processor_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(processor_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_files = [\n",
    "#         \"Hotel_Taxi.pdf\",\n",
    "#         \"taxi_to_airport_barc.pdf\",\n",
    "#         \"car_sharing_first_day.pdf\",\n",
    "#         \"flight.pdf\"\n",
    "#     ]\n",
    "\n",
    "list_of_files = [\n",
    "        \"Bolt to GS 2.pdf\",\n",
    "        # \"Bolt to GS.pdf\",\n",
    "        \"Hotel.pdf\",\n",
    "        # \"Hotel_Taxi.pdf\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da84358",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"file_names\": list_of_files,\n",
    "    \"current_index\": 0,\n",
    "    \"entities\": [],\n",
    "    \"inferred_types\": []\n",
    "}\n",
    "\n",
    "result = await processor_graph.ainvoke(initial_state)\n",
    "\n",
    "# Add the inferred types to the entities for later use\n",
    "for i,typ in enumerate(result[\"inferred_types\"]):\n",
    "    result[\"entities\"][i][\"invoice_type\"] = typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720927f",
   "metadata": {},
   "source": [
    "Create Markdown summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(result[\"summary\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c487d38",
   "metadata": {},
   "source": [
    "### Wrapped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8072562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finance_analysis.resources.agent import ProcessorGraph\n",
    "\n",
    "directory = \"Graphisoft, Budapest, Mar\"\n",
    "# directory = \"Barcelona\"\n",
    "root_directory = '/Users/avosseler/Business Trips/2025'\n",
    "target_dir = os.path.join(root_directory, directory)\n",
    "target_xlsx_file = \"my_travel_expense.xlsx\"\n",
    "\n",
    "# list_of_files = [\n",
    "#         \"Hotel_Taxi.pdf\",\n",
    "#         \"taxi_to_airport_barc.pdf\",\n",
    "#         \"car_sharing_first_day.pdf\",\n",
    "#         \"flight.pdf\"\n",
    "#     ]\n",
    "\n",
    "list_of_files = [\n",
    "        # \"Bolt to GS 2.pdf\",\n",
    "        \"Bolt to GS.pdf\",\n",
    "        \"Hotel.pdf\",\n",
    "        # \"Hotel_Taxi.pdf\",\n",
    "    ]\n",
    "\n",
    "supervisor = ProcessorGraph(list_of_files=list_of_files, source_path=target_dir, target_xls_file=target_xlsx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4deac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await supervisor.ainvoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423cf8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(result[\"summary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b0bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"entities\"]#[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ff6c5",
   "metadata": {},
   "source": [
    "### Update XLS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af897142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.workbook.properties import CalcProperties\n",
    "\n",
    "dir_name = \"/Users/avosseler/Business Trips/2025/tmp\"\n",
    "pfile = os.path.join(dir_name, 'Travel Expense Tmp.xlsx')\n",
    "\n",
    "# Load your workbook (make sure data_only=False so formulas are preserved)\n",
    "wb = load_workbook(pfile, data_only=False)\n",
    "\n",
    "# Select the sheet you want to modify\n",
    "ws = wb['RKA Seite 1']\n",
    "\n",
    "# Overwrite the cells that feed into formulas\n",
    "ws['C2'] = \"Vosseler, Alexander\"\n",
    "ws['E2'] = \"100392\"  # cost center\n",
    "ws['E3'] = \"Munich\"                # location\n",
    "ws['C6'] = \"Barcelona\"             # destination\n",
    "ws['C7'] = \"Workshop\"          # Reason for travel\n",
    "\n",
    "rowA = 19; entries = 1; rowB = 29\n",
    "for res in result[\"entities\"]:\n",
    "    if res['invoice_type'] == \"hotel\":\n",
    "        ws[f\"A{rowA}\"] = res['checkin_date']\n",
    "        ws[f\"B{rowA}\"] = entries\n",
    "        ws[f\"C{rowA}\"] = res['description']\n",
    "        ws[f\"E{rowA}\"] = res['total_amount']\n",
    "        rowA += 1\n",
    "    else:\n",
    "        ws[f\"A{rowB}\"] = res['issue_date']\n",
    "        ws[f\"B{rowB}\"] = entries\n",
    "        ws[f\"C{rowB}\"] = res['description']\n",
    "        ws[f\"E{rowB}\"] = res['total_amount']\n",
    "        rowB += 1\n",
    "    entries += 1\n",
    "    \n",
    "ws[f\"C{rowB+2}\"] = result[\"rate_info\"]  # Add exchange rate info\n",
    "        \n",
    "# Manually attach CalcProperties to force full recalc on load\n",
    "wb._calculation_properties = CalcProperties(fullCalcOnLoad=True)\n",
    "\n",
    "# Save to a new file (or overwrite)\n",
    "wb.save(os.path.join(dir_name, 'Travel Expense Tmp Edt2.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2131f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws2 = wb['RKA Seite 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.workbook.properties import CalcProperties\n",
    "\n",
    "def update_travel_expense_xlsx(\n",
    "    result,\n",
    "    trip_metadata={\"Last/First name\": \"Vosseler, Alexander\", \n",
    "                   \"Location\": \"Munich\", \n",
    "                   \"Destination\": \"Barcelona\", \n",
    "                   \"Cost Center\": \"100392\",\n",
    "                   \"Reason for travel\": \"Workshop\"},\n",
    "    dir_name=\"/Users/avosseler/Business Trips/2025/tmp\",\n",
    "    input_file=\"Travel Expense Tmp.xlsx\",\n",
    "    output_file=\"Travel Expense Tmp Edt.xlsx\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the travel expense Excel file with extracted invoice data.\n",
    "\n",
    "    Args:\n",
    "        result (dict): The result dictionary containing invoice entities.\n",
    "        dir_name (str): Directory containing the Excel file.\n",
    "        input_file (str): Name of the input Excel file.\n",
    "        output_file (str): Name of the output Excel file.\n",
    "        sheet_name (str): Name of the worksheet to update.\n",
    "    \"\"\"\n",
    "    pfile = os.path.join(dir_name, input_file)\n",
    "    wb = load_workbook(pfile, data_only=False)\n",
    "    ws = wb[\"RKA Seite 1\"]\n",
    "    \n",
    "    # --------------------------- Sheet 1 ------------------------------------\n",
    "    # Overwrite the cells that feed into formulas\n",
    "    ws['C2'] = trip_metadata.get(\"Last/First name\", \"Vosseler, Alexander\")\n",
    "    ws['E2'] = trip_metadata.get(\"Cost Center\", \"100392\")  # cost center\n",
    "    ws['E3'] = trip_metadata.get(\"Location\", \"Munich\")  # location\n",
    "    ws['C6'] = trip_metadata.get(\"Destination\", \"Barcelona\")  # destination\n",
    "    ws['C7'] = trip_metadata.get(\"Reason for travel\", \"Workshop\")  # Reason for travel\n",
    "\n",
    "    rowA = 19\n",
    "    entries = 1\n",
    "    rowB = 29\n",
    "    for res in result[\"entities\"]:\n",
    "        if res['invoice_type'] == \"hotel\":\n",
    "            ws[f\"A{rowA}\"] = res['checkin_date']\n",
    "            ws[f\"B{rowA}\"] = entries\n",
    "            ws[f\"C{rowA}\"] = res['description']\n",
    "            ws[f\"E{rowA}\"] = res['total_amount']\n",
    "            rowA += 1\n",
    "        else:\n",
    "            ws[f\"A{rowB}\"] = res['issue_date']\n",
    "            ws[f\"B{rowB}\"] = entries\n",
    "            ws[f\"C{rowB}\"] = res['description']\n",
    "            ws[f\"E{rowB}\"] = res['total_amount']\n",
    "            rowB += 1\n",
    "        entries += 1\n",
    "\n",
    "    ws[f\"C{rowB+2}\"] = result[\"rate_info\"]  # Add exchange rate info\n",
    "    \n",
    "    # --------------------------- Sheet 2 ------------------------------------\n",
    "    ws2 = wb['RKA Seite 2']\n",
    "\n",
    "    # Manually attach CalcProperties to force full recalc on load\n",
    "    wb._calculation_properties = CalcProperties(fullCalcOnLoad=True)\n",
    "\n",
    "    # Save to a new file (or overwrite)\n",
    "    wb.save(os.path.join(dir_name, output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af73797",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_travel_expense_xlsx(\n",
    "    result,\n",
    "    trip_metadata={\n",
    "        \"Last/First name\": \"Vosseler, Alexander\",\n",
    "        \"Location\": \"Munich\",\n",
    "        \"Destination\": \"Barcelona\",\n",
    "        \"Reason for travel\": \"Workshop\"\n",
    "    },\n",
    "    dir_name=\"/Users/avosseler/Business Trips/2025/tmp\",\n",
    "    input_file=\"Travel Expense Tmp.xlsx\",\n",
    "    output_file=\"Travel Expense Tmp Edt3.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6a8245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invoice-agent-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
